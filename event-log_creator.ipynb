{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event-log creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filepath for saving\n",
    "file_path_general = 'your_filepath'\n",
    "\n",
    "# Set date format\n",
    "date_format = \"%d.%m.%Y %H:%M\"\n",
    "new_date_format = \"%Y-%m-%d %H:%M:%S\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Auftragsnummer</th>\n",
       "      <th>Versand_ID</th>\n",
       "      <th>Verladestart</th>\n",
       "      <th>Verladeende</th>\n",
       "      <th>Versand_SOLL</th>\n",
       "      <th>Lagereinheit_ID</th>\n",
       "      <th>Packplatz</th>\n",
       "      <th>Packzeitpunkt</th>\n",
       "      <th>Menge</th>\n",
       "      <th>Lagerort_von</th>\n",
       "      <th>Lagerort_nach</th>\n",
       "      <th>Startzeitpunkt</th>\n",
       "      <th>Endzeitpunkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1008</td>\n",
       "      <td>80939</td>\n",
       "      <td>27.05.2022 21:25</td>\n",
       "      <td>28.05.2022 01:23</td>\n",
       "      <td>27.05.2022 21:55</td>\n",
       "      <td>231</td>\n",
       "      <td>Packplatz 03</td>\n",
       "      <td>27.05.2022 19:46</td>\n",
       "      <td>447</td>\n",
       "      <td>Wareneingang</td>\n",
       "      <td>Hochregallager</td>\n",
       "      <td>2022-05-27 05:18:00</td>\n",
       "      <td>2022-05-27 07:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1008</td>\n",
       "      <td>80939</td>\n",
       "      <td>27.05.2022 21:25</td>\n",
       "      <td>28.05.2022 01:23</td>\n",
       "      <td>27.05.2022 21:55</td>\n",
       "      <td>231</td>\n",
       "      <td>Packplatz 03</td>\n",
       "      <td>27.05.2022 19:46</td>\n",
       "      <td>447</td>\n",
       "      <td>Hochregallager</td>\n",
       "      <td>Packplatz</td>\n",
       "      <td>2022-05-27 17:38:00</td>\n",
       "      <td>2022-05-27 18:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011</td>\n",
       "      <td>53941</td>\n",
       "      <td>27.05.2022 22:05</td>\n",
       "      <td>27.05.2022 23:38</td>\n",
       "      <td>27.05.2022 22:35</td>\n",
       "      <td>763</td>\n",
       "      <td>Packplatz 09</td>\n",
       "      <td>27.05.2022 21:17</td>\n",
       "      <td>165</td>\n",
       "      <td>Hochregallager</td>\n",
       "      <td>Packplatz</td>\n",
       "      <td>2022-05-27 16:25:00</td>\n",
       "      <td>2022-05-27 17:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1011</td>\n",
       "      <td>53941</td>\n",
       "      <td>27.05.2022 22:05</td>\n",
       "      <td>27.05.2022 23:38</td>\n",
       "      <td>27.05.2022 22:35</td>\n",
       "      <td>763</td>\n",
       "      <td>Packplatz 09</td>\n",
       "      <td>27.05.2022 21:17</td>\n",
       "      <td>165</td>\n",
       "      <td>Wareneingang</td>\n",
       "      <td>Hochregallager</td>\n",
       "      <td>2022-05-27 17:16:00</td>\n",
       "      <td>2022-05-27 18:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018</td>\n",
       "      <td>85216</td>\n",
       "      <td>28.05.2022 01:02</td>\n",
       "      <td>28.05.2022 03:55</td>\n",
       "      <td>28.05.2022 01:32</td>\n",
       "      <td>770</td>\n",
       "      <td>Packplatz 04</td>\n",
       "      <td>28.05.2022 00:09</td>\n",
       "      <td>317</td>\n",
       "      <td>Wareneingang</td>\n",
       "      <td>Hochregallager</td>\n",
       "      <td>2022-05-27 09:37:00</td>\n",
       "      <td>2022-05-27 11:19:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Auftragsnummer  Versand_ID      Verladestart       Verladeende  \\\n",
       "0            1008       80939  27.05.2022 21:25  28.05.2022 01:23   \n",
       "1            1008       80939  27.05.2022 21:25  28.05.2022 01:23   \n",
       "2            1011       53941  27.05.2022 22:05  27.05.2022 23:38   \n",
       "3            1011       53941  27.05.2022 22:05  27.05.2022 23:38   \n",
       "4            1018       85216  28.05.2022 01:02  28.05.2022 03:55   \n",
       "\n",
       "       Versand_SOLL  Lagereinheit_ID     Packplatz     Packzeitpunkt  Menge  \\\n",
       "0  27.05.2022 21:55              231  Packplatz 03  27.05.2022 19:46    447   \n",
       "1  27.05.2022 21:55              231  Packplatz 03  27.05.2022 19:46    447   \n",
       "2  27.05.2022 22:35              763  Packplatz 09  27.05.2022 21:17    165   \n",
       "3  27.05.2022 22:35              763  Packplatz 09  27.05.2022 21:17    165   \n",
       "4  28.05.2022 01:32              770  Packplatz 04  28.05.2022 00:09    317   \n",
       "\n",
       "     Lagerort_von   Lagerort_nach       Startzeitpunkt         Endzeitpunkt  \n",
       "0    Wareneingang  Hochregallager  2022-05-27 05:18:00  2022-05-27 07:42:00  \n",
       "1  Hochregallager       Packplatz  2022-05-27 17:38:00  2022-05-27 18:27:00  \n",
       "2  Hochregallager       Packplatz  2022-05-27 16:25:00  2022-05-27 17:44:00  \n",
       "3    Wareneingang  Hochregallager  2022-05-27 17:16:00  2022-05-27 18:42:00  \n",
       "4    Wareneingang  Hochregallager  2022-05-27 09:37:00  2022-05-27 11:19:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "file_path = 'your_filepath/syntetic_merged_data.csv'\n",
    "df = pd.read_csv(file_path ,sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set process activities\n",
    "process_activities = ['Ware vereinnahmen', 'Waren lagern', 'Waren kommissionieren', 'Waren im Warenausgang', 'Waren verladen']\n",
    "\n",
    "# Set storage location\n",
    "storage_locations = ['Wareneingang', 'Hochregallager', 'Packplatz', 'Warenausgang', 'Transportmittel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list with all Auftragsnummern \n",
    "auftragsnummern = df['Auftragsnummer'].unique().tolist()\n",
    "\n",
    "# Group data after Auftragsnummer\n",
    "grouped_data = df.groupby('Auftragsnummer') \n",
    "\n",
    "# Make a new pandas dataframe\n",
    "df_new = pd.DataFrame(columns=['case_id', 'process_activity', 'Auftragsnummer', 'Versand_ID', 'Verladestart', 'Verladeende', 'Versand_SOLL', 'Lagereinheit_ID', 'Packplatz', 'Packzeitpunkt', 'Menge', 'Lagerort_von', 'Lagerort_nach', 'Startzeitpunkt', 'Endzeitpunkt', 'Verspaetung', 'Lagerort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Restrictions:\n",
    "#   - n * 'Auftragsnummern' can shiped in n * parcels ('Versand_ID'). \n",
    "#   - But only 1x parcel ('Versand_ID') can only include 1x 'Auftragsnummer'\n",
    "\n",
    "# Get the WMS-movement rows for a unique event\n",
    "# A unique event is defined by a 'Versand_ID' and 'Auftragsnummer'. Because of the restriction that 1x parcel can only include 1x 'Auftragsnummer',\n",
    "# the relationship is 1 to 1 between #Versand_ID' and 'Auftragsnummer'. This is also the reason, why the 'Versand_ID' builds the Case_ID.\n",
    "# The case_id shows all related WMS-movements.\n",
    "\n",
    "# For the above descripted reason, there are two nested for-loops. Every loop groupes the dataframe further.\n",
    "# The first input dataframe is a df grouped by 'Auftragsnummer', the second is grpuped by 'Versand_ID'.\n",
    "# Lastly we get every time two WMS-movements and creates due to this the needed rows for the event-log. \n",
    "\n",
    "for i in auftragsnummern:\n",
    "    case_data1 = grouped_data.get_group(i)\n",
    "    versand_ids = case_data1['Versand_ID'].unique().tolist() #unique() kann entfernt werden, da Versand IDs sowieso einzigartig sind\n",
    "    grouped_versand_ids = case_data1.groupby('Versand_ID')\n",
    "        \n",
    "    for b in versand_ids:\n",
    "        how = grouped_versand_ids.get_group(b)\n",
    "        case_data = grouped_versand_ids.get_group(b).sort_values(by='Lagerort_von', ascending=False).reset_index(drop=True)\n",
    "        print(case_data)\n",
    "\n",
    "        num_new_dfs = len(case_data) // 2\n",
    "        \n",
    "        # Create new dataframes with the length of only two elements. Every 'Versand_ID' has only one 'Auftragsnummer', because of the restriction described above. \n",
    "        # But one Auftrag can shiped in different parcels. Furthermore different articels ('Lagereinheiten_ID') can picked in one parcel ('Versand_ID').\n",
    "        # Thats the reason why we got not every time only two elements after we grouped by 'Versand_ID'. So we have to group further to seperate the not belonging WMS-movements.\n",
    "        # That is done by take the related WMS-movements with a for and while-loop from the pre-grouped and sorted case_data.\n",
    "        for i in range(num_new_dfs):\n",
    "          new_case_data_df = pd.DataFrame()\n",
    "          choose_elements = i\n",
    "          c = 0\n",
    "          while c < 2:\n",
    "            new_case_data_df = new_case_data_df.append(case_data.iloc[choose_elements], ignore_index=True)\n",
    "            choose_elements = choose_elements + num_new_dfs\n",
    "            c = c+1\n",
    "          \n",
    "          print(new_case_data_df)\n",
    "\n",
    "        # Create case_id from 'Versand_ID'\n",
    "        case_id = str(b) \n",
    "\n",
    "        # Get current Index\n",
    "        current_index = new_case_data_df.index[0]\n",
    "\n",
    "        # Check if the process have a delay\n",
    "        if new_case_data_df.at[current_index, 'Versand_SOLL'] < new_case_data_df.at[current_index, 'Verladeende']:\n",
    "          delay = True\n",
    "        else:\n",
    "          delay = False\n",
    "\n",
    "        # Choose current row\n",
    "        current_row = new_case_data_df.iloc[0]  \n",
    "\n",
    "        current_row_copy = current_row.copy()\n",
    "\n",
    "        # Get values from current row\n",
    "        cu_lagerort_nach = current_row['Lagerort_nach']\n",
    "        cu_endzeitpunkt = current_row['Endzeitpunkt']\n",
    "        cu_startzeitpunkt = current_row['Startzeitpunkt']\n",
    "\n",
    "        # Get values from the directly following row\n",
    "        next_row = new_case_data_df.iloc[1]\n",
    "        ne_startzeitpunkt = next_row['Startzeitpunkt']\n",
    "        ne_endzeitpunkt = next_row['Endzeitpunkt']\n",
    "\n",
    "        # Prepare new line to implement\n",
    "        current_row_copy['Lagerort_von'] = cu_lagerort_nach\n",
    "        current_row_copy['Startzeitpunkt'] = cu_endzeitpunkt\n",
    "        current_row_copy['Endzeitpunkt'] = ne_startzeitpunkt\n",
    "        current_row_copy['case_id'] = case_id\n",
    "        current_row_copy['process_activity'] = process_activities[1]\n",
    "        current_row_copy['Verspaetung'] = delay\n",
    "        current_row_copy['Lagerort'] = storage_locations[1]\n",
    "\n",
    "        # Prepare lines\n",
    "        # Modify current line\n",
    "        new_case_data_df.at[current_index, 'case_id'] = case_id\n",
    "        new_case_data_df.at[current_index, 'process_activity'] = process_activities[0]\n",
    "        new_case_data_df.at[current_index, 'Verspaetung'] = delay\n",
    "        new_case_data_df.at[current_index, 'Lagerort'] = storage_locations[0]\n",
    "\n",
    "        # Modify the next following line\n",
    "        new_case_data_df.at[current_index+1, 'case_id'] = case_id\n",
    "        new_case_data_df.at[current_index+1, 'process_activity'] = process_activities[2]\n",
    "        new_case_data_df.at[current_index+1, 'Verspaetung'] = delay\n",
    "        new_case_data_df.at[current_index+1, 'Lagerort'] = storage_locations[2]\n",
    "\n",
    "        # Paste the copied line below the current line\n",
    "        df2 = pd.concat([new_case_data_df.iloc[:current_index+1], current_row_copy.to_frame().T, new_case_data_df.iloc[current_index+1:]]).reset_index(drop=True)\n",
    "\n",
    "        # Append activities 'Waren im Warenausgang' \n",
    "        # Get needed values from current row\n",
    "        cu_wareneingang_start = new_case_data_df.loc[current_index+1, 'Endzeitpunkt']\n",
    "\n",
    "        parsed_date_end = datetime.strptime(current_row['Verladestart'], date_format)\n",
    "        formatted_date_end = parsed_date_end.strftime(new_date_format)\n",
    "        cu_wareneingang_ende = formatted_date_end\n",
    "        \n",
    "\n",
    "        current_row_copy['case_id'] = case_id\n",
    "        current_row_copy['Startzeitpunkt'] = cu_wareneingang_start\n",
    "        current_row_copy['Endzeitpunkt'] = cu_wareneingang_ende\n",
    "        current_row_copy['process_activity'] = process_activities[3]\n",
    "        current_row_copy['Verspaetung'] = delay\n",
    "        current_row_copy['Lagerort'] = storage_locations[3]\n",
    "        current_row_copy['Lagerort_von'] = 'Packplatz'\n",
    "        current_row_copy['Lagerort_nach'] = 'Warenausgang'\n",
    "\n",
    "        df2 = df2.append(current_row_copy, ignore_index=True)\n",
    "\n",
    "        # Append activities 'Waren verladen'\n",
    "        cu_verladestart = formatted_date_end\n",
    "        parsed_date_end2 = datetime.strptime(current_row['Verladeende'], date_format)\n",
    "        formatted_date_end2 = parsed_date_end2.strftime(new_date_format)\n",
    "        cu_verladeende = formatted_date_end2\n",
    "\n",
    "        # Current_row_copy2['case_id'] = case_id\n",
    "        current_row_copy['Startzeitpunkt'] = cu_verladestart\n",
    "        current_row_copy['Endzeitpunkt'] = cu_verladeende\n",
    "        current_row_copy['process_activity'] = process_activities[4]\n",
    "        current_row_copy['Verspaetung'] = delay\n",
    "        current_row_copy['Lagerort'] = storage_locations[4]\n",
    "        current_row_copy['Lagerort_von'] = 'Warenausgang'\n",
    "        current_row_copy['Lagerort_nach'] = 'Transportmittel'\n",
    "\n",
    "        df2 = df2.append(current_row_copy, ignore_index=True)\n",
    "\n",
    "\n",
    "        df_new = df_new.append(df2, ignore_index=True)\n",
    "\n",
    "        \n",
    "  \n",
    "    \n",
    "file_path = file_path_general + 'event-log.csv'\n",
    "df_new.to_csv(file_path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short event-log\n",
    "# Creates rows only with the needed informations\n",
    "df_short = df_new.copy()\n",
    "df_short.drop(['Versand_ID', 'Verladestart', 'Verladeende', 'Versand_SOLL', 'Lagereinheit_ID', 'Packplatz', 'Packzeitpunkt'], axis=1, inplace=True)\n",
    "\n",
    "file_path = file_path_general + \"event-log_short.csv\"\n",
    "df_short.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_PM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
