{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntetic data-generator with Faker\n",
    "### 1. Create data-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose number of datasamples\n",
    "num_samples = 1000\n",
    "\n",
    "# Set filepath for saving\n",
    "file_path_general = 'C:/Users/f_obersteiner/Desktop/Testdaten/final_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate valid data for Versand-data\n",
    "current_time = datetime.now()\n",
    "random_month = random.randint(1, 12)\n",
    "one_year_ago = current_time.replace(year=current_time.year-1, month=random_month)\n",
    "# print(one_year_ago)\n",
    "\n",
    "# Initialisieren des Faker-Moduls\n",
    "fake = Faker()\n",
    "\n",
    "# Generieren von Daten für eine neue Zeile\n",
    "def generate_valid_data():\n",
    "    startzeitpunkt = one_year_ago\n",
    "    dif_minutes = fake.random_int(min=2, max=240)\n",
    "    endzeitpunkt = startzeitpunkt + timedelta(minutes=dif_minutes)\n",
    "    # print(\"Endzeitpunkt: \" + endzeitpunkt.strftime('%d.%m.%Y %H:%M'))\n",
    "    dif_minutes1 = fake.random_int(min=2, max=240)\n",
    "    packzeitpunkt = endzeitpunkt + timedelta(minutes=dif_minutes1)\n",
    "    # print(\"Packzeitpunkt: \" + packzeitpunkt.strftime('%d.%m.%Y %H:%M'))\n",
    "    dif_minutes2 = fake.random_int(min=2, max=240)\n",
    "    verladestart = packzeitpunkt + timedelta(minutes=dif_minutes2)\n",
    "    # print(\"Verladestart: \" + verladestart.strftime('%d.%m.%Y %H:%M'))\n",
    "    dif_minutes3 = fake.random_int(min=2, max=240)\n",
    "    verladeende = verladestart + timedelta(minutes=dif_minutes3)\n",
    "    # print(\"Verladeende: \" + verladeende.strftime('%d.%m.%Y %H:%M'))\n",
    "\n",
    "    #auftragsnummer = fake.random_int(min=100, max=999)\n",
    "    #auftragsnummer = fake.pyint(min_value=100, max_value=999)\n",
    "\n",
    "    # Es wird zuerst der Mittelwert mu und die Standardabweichung sigma für die Normalverteilung definiert. \n",
    "    # Dann wird die Methode random_int() verwendet. \n",
    "    # Der min-Parameter wird auf eine zufällige Zahl gesetzt, die aus einer Normalverteilung mit dem Mittelwert mu und der Standardabweichung sigma stammt. \n",
    "    # Der step-Parameter wird zufällig aus den Werten 1, 2 oder 3 gewählt. Dadurch wird sichergestellt, dass einige der zufälligen Zahlen doppelt oder dreifach vorkommen können.\n",
    "    \n",
    "    # Mittelwert und Standardabweichung für die Normalverteilung\n",
    "    mu = 50\n",
    "    sigma = 10\n",
    "    # Erstellen einer Auftragsnummer mit 4 Zeichen\n",
    "    #auftragsnummer = fake.random_int(min=int(np.random.normal(mu, sigma)), max=9999, step=random.choice([1, 2, 3]))\n",
    "    # Die generierte Zahl wird mit np.random.normal(mu, sigma) erzeugt und dann mit np.round() auf vier Stellen gerundet. \n",
    "    # Die gerundete Zahl wird dann mit der max()-Funktion verglichen, um sicherzustellen, dass sie mindestens vier Stellen hat. \n",
    "    # Wenn die gerundete Zahl kleiner als 1000 ist, wird sie auf 1000 gesetzt. \n",
    "    # Das Ergebnis ist eine normalverteilte Zufallszahl mit mindestens vier Stellen.\n",
    "    auftragsnummer = fake.random_int(min=max(int(np.round(np.random.normal(mu, sigma))), 1000), max=9999, step=random.choice([1, 2, 3]))\n",
    "\n",
    "    versand_id = fake.random_int(min=10, max=99)\n",
    "    verladestart_str = verladestart.strftime('%d.%m.%Y %H:%M')\n",
    "    verladeende_str = verladeende.strftime('%d.%m.%Y %H:%M')\n",
    "    versand_soll_str = (\n",
    "        verladestart + timedelta(minutes=30)).strftime('%d.%m.%Y %H:%M')\n",
    "\n",
    "    # Erstellen der neuen Datenreihe als Liste\n",
    "    new_row = [auftragsnummer, versand_id, verladestart_str, verladeende_str, versand_soll_str]\n",
    "\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Create  Versand-data-file as csv\n",
    "df_VER = pd.DataFrame(columns=['Auftragsnummer', 'Versand_ID', 'Verladestart', 'Verladeende', 'Versand_SOLL'])\n",
    "    # Schleife über die Anzahl der Datensätze\n",
    "for i in range(num_samples):\n",
    "    # Schreiben der neuen Zeile in die CSV-Datei\n",
    "    new_row = generate_valid_data()\n",
    "    # print(new_row)\n",
    "    df_VER = df_VER.append(pd.Series(new_row, index=df_VER.columns), ignore_index=True)\n",
    "    \n",
    "file_path = file_path_general + \"syntetic_VER_data.csv\"\n",
    "df_VER.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate valid data for Kommissionier-data\n",
    "\n",
    "# Initialisieren des Faker-Moduls\n",
    "fake = Faker()\n",
    "\n",
    "# Generieren von Daten für eine neue Zeile\n",
    "\n",
    "\n",
    "def generate_valid_data2(verladestart_ue, auftragsnummer_ue):\n",
    "  \n",
    "    verladestart_to_date = datetime.strptime(verladestart_ue, '%d.%m.%Y %H:%M')\n",
    "    dif_minutes1 = fake.random_int(min=2, max=240)\n",
    "    packzeitpunkt = verladestart_to_date - timedelta(minutes=dif_minutes1)\n",
    "\n",
    "    auftragsnummer = auftragsnummer_ue\n",
    "    lagereinheit_id = fake.random_int(min=100, max=999)\n",
    "    packplatz = \"Packplatz \" + str(random.randint(1, 10)).zfill(2)\n",
    "    packzeitpunkt_str = packzeitpunkt.strftime('%d.%m.%Y %H:%M')\n",
    "    menge = fake.random_int(min=1, max=500)\n",
    "\n",
    "    # Erstellen der neuen Datenreihe als Liste\n",
    "    new_row = [lagereinheit_id, packplatz, auftragsnummer, packzeitpunkt_str, menge]\n",
    "\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Create  KOM-data-file as csv\n",
    "df_KOM = pd.DataFrame(columns=['Lagereinheit_ID', 'Packplatz', 'Auftragsnummer', 'Packzeitpunkt', 'Menge'])\n",
    "\n",
    "    # Schleife über die Anzahl der Datensätze\n",
    "for i in range(num_samples):\n",
    "    # Schreiben der neuen Zeile in die CSV-Datei\n",
    "    new_row = generate_valid_data2(df_VER.iloc[i, 2], df_VER.iloc[i, 0])\n",
    "    # print(new_row)\n",
    "    df_KOM = df_KOM.append(pd.Series(new_row, index=df_KOM.columns), ignore_index=True)\n",
    "\n",
    "file_path = file_path_general + \"syntetic_KOM_data.csv\"\n",
    "df_KOM.to_csv(file_path, index=False)\n",
    "\n",
    "print(df_KOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate valid data for WMS-data\n",
    "\n",
    "# Initialisieren des Faker-Moduls\n",
    "fake = Faker()\n",
    "\n",
    "# Generieren von Daten für eine neue Zeile\n",
    "\n",
    "\n",
    "def generate_valid_data3(lagereinheit_id_ue, packzeitpunkt_ue, lagerort_von_ue, startzeitpunkt_ue):\n",
    "    \n",
    "    packzeitpunkt_to_date = datetime.strptime(packzeitpunkt_ue, '%d.%m.%Y %H:%M')\n",
    "    startzeitpunkt_to_date = datetime.strptime(startzeitpunkt_ue, '%d.%m.%Y %H:%M')\n",
    "    \n",
    "\n",
    "    \n",
    "    lagereinheit_id = lagereinheit_id_ue\n",
    "\n",
    "    if lagerort_von_ue == 'Wareneingang':\n",
    "     lagerort_von = 'Wareneingang'\n",
    "     lagerort_nach = 'Hochregallager'\n",
    "     dif_minutes1 = fake.random_int(min=2, max=240)\n",
    "     endzeitpunkt = startzeitpunkt_to_date - timedelta(minutes=dif_minutes1)\n",
    "     dif_minutes2 = fake.random_int(min=2, max=240)\n",
    "     startzeitpunkt = endzeitpunkt - timedelta(minutes=dif_minutes2)\n",
    "    else: \n",
    "     lagerort_von = 'Hochregallager'\n",
    "     lagerort_nach = 'Packplatz'\n",
    "     dif_minutes1 = fake.random_int(min=2, max=240)\n",
    "     endzeitpunkt = packzeitpunkt_to_date - timedelta(minutes=dif_minutes1)\n",
    "     dif_minutes2 = fake.random_int(min=2, max=240)\n",
    "     startzeitpunkt = endzeitpunkt - timedelta(minutes=dif_minutes2)\n",
    "\n",
    "    # Erstellen der neuen Datenreihe als Liste\n",
    "    new_row = [lagereinheit_id, lagerort_von, lagerort_nach, startzeitpunkt, endzeitpunkt]\n",
    "\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Create  WMS-data-file as csv\n",
    "df_WMS = pd.DataFrame(columns=['Lagereinheit_ID', 'Lagerort_von', 'Lagerort_nach', 'Startzeitpunkt', 'Endzeitpunkt'])\n",
    "\n",
    "# Schleife über die Anzahl der Datensätze\n",
    "a = 0\n",
    "while a < num_samples:\n",
    "   # print(a)\n",
    "    lagereinheit_von_ue = 'Hochregallager'\n",
    "    startzeitpunkt_ue = df_KOM.iloc[a, 3]\n",
    "    #print(startzeitpunkt_ue)\n",
    "   \n",
    "    for i in range(2):\n",
    "        #print(i)\n",
    "        # Schreiben der neuen Zeile in die CSV-Datei\n",
    "        new_row = generate_valid_data3(df_KOM.iloc[a, 0], df_KOM.iloc[a, 3], lagereinheit_von_ue, startzeitpunkt_ue)\n",
    "        # print(new_row)\n",
    "        df_WMS = df_WMS.append(pd.Series(new_row, index=df_WMS.columns), ignore_index=True)\n",
    "\n",
    "        lagereinheit_von_ue = 'Wareneingang'\n",
    "        startzeitpunkt_ue = df_WMS.iloc[a, 3].strftime('%d.%m.%Y %H:%M')\n",
    "        #endzeitpunkt_ue = df_WMS.iloc[a, 4]\n",
    "\n",
    "    a = a + 1\n",
    "       \n",
    "        #print(i)\n",
    "        \n",
    "#delete duplicates of Lagereinheit_ID\n",
    "#Überprüfen welche Zeilen doppelte Werte in der Spalte haben\n",
    "duplicates = df_WMS.duplicated(subset='Lagereinheit_ID')\n",
    "\n",
    "#Löschen der doppelten Zeilen aus dem Dataframe\n",
    "df_WMS_unique = df_WMS.drop_duplicates(subset=['Lagereinheit_ID', 'Lagerort_von'])\n",
    "\n",
    "file_path = file_path_general + \"syntetic_WMS_data.csv\"\n",
    "df_WMS_unique.to_csv(file_path, index=False)\n",
    "\n",
    "#print(df_WMS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Merge datatables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "data_WMS = pd.read_csv('C:/Users/f_obersteiner/Desktop/Testdaten/final_data/syntetic_WMS_data.csv', delimiter=',')\n",
    "data_KOM = pd.read_csv('C:/Users/f_obersteiner/Desktop/Testdaten/final_data/syntetic_KOM_data.csv', delimiter=',')\n",
    "data_VER = pd.read_csv('C:/Users/f_obersteiner/Desktop/Testdaten/final_data/syntetic_VER_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "data_VER_KOM = data_VER.merge(data_KOM, left_on='Auftragsnummer', right_on='Auftragsnummer')\n",
    "# print(data_VER_KOM)\n",
    "data_VER_KOM_WMS = data_VER_KOM.merge(data_WMS, left_on='Lagereinheit_ID', right_on='Lagereinheit_ID')\n",
    "\n",
    "# 'Datum'-Spalte in ein datetime-Objekt konvertieren\n",
    "data_VER_KOM_WMS['Startzeitpunkt'] = pd.to_datetime(data_VER_KOM_WMS['Startzeitpunkt'])\n",
    "\n",
    "# sort by 'Auftragsnummer' und 'Startzeitpunkt' in ascending order\n",
    "data_VER_KOM_WMS.sort_values(by=['Auftragsnummer', 'Startzeitpunkt'], inplace=True)\n",
    "# print(data_VER_KOM_WMS['Auftragsnummer'])\n",
    "\n",
    "# create csv\n",
    "file_path = file_path_general + \"syntetic_merged_data.csv\"\n",
    "data_VER_KOM_WMS.to_csv(file_path, sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_PM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
